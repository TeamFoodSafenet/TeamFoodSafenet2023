{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987da0a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import xgboost as xgb\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a92990",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "\n",
    "uri = \"bolt://localhost:7687\"  \n",
    "username = \"neo4j\"     \n",
    "password = \"foodContamination\" #This is whatever password you set when you are created your database    \n",
    "\n",
    "driver = GraphDatabase.driver(uri, auth=(username, password))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b116b131",
   "metadata": {},
   "outputs": [],
   "source": [
    "cypher_query = \"\"\"MATCH (n) \n",
    "OPTIONAL MATCH (n)-[r]->(m) \n",
    "RETURN n, r, m\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04179c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with driver.session() as session:\n",
    "    result = session.run(cypher_query)\n",
    "\n",
    "    # Extract properties and relationships from nodes\n",
    "    data = []\n",
    "    for record in result:\n",
    "        node = record['n']\n",
    "        properties = dict(node.items())\n",
    "        relationship = record['r']\n",
    "        if relationship is not None:\n",
    "            relationship_properties = dict(relationship.items())\n",
    "        else:\n",
    "            relationship_properties = {}\n",
    "        data.append({**properties, **relationship_properties})\n",
    "\n",
    "    # Create DataFrame from the data\n",
    "    df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71127bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[['commodity','eventID', 'gtin', 'sgln', 'cteDate', 'pgln', 'contaminated', 'shortDescription']]\n",
    "df2 = df2.dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a828ef02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['cteDate'] = pd.to_datetime(df2['cteDate'])\n",
    "reference_date = pd.to_datetime('1970-01-01')\n",
    "df2['cteDate'] = (df2['cteDate'] - reference_date).dt.days.astype(float)\n",
    "\n",
    "df2['commodity'] = df2['commodity'].fillna(df2['shortDescription'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746daf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.drop('shortDescription', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dde6fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2['eventID'] = pd.to_numeric(df2['eventID'].str.replace('.', ''))\n",
    "df2['gtin'] = pd.to_numeric(df2['gtin'].str.replace('.', ''))\n",
    "df2['sgln'] = pd.to_numeric(df2['sgln'].str.replace('.', ''))\n",
    "df2['pgln'] = pd.to_numeric(df2['pgln'].str.replace('.', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f814bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the columns to be one-hot encoded\n",
    "columns_to_encode = ['commodity']\n",
    "\n",
    "# Create the ColumnTransformer\n",
    "transformer = ColumnTransformer([('one_hot_encoder', OneHotEncoder(), columns_to_encode)], remainder='passthrough')\n",
    "\n",
    "# Apply the transformation\n",
    "df_encoded = transformer.fit_transform(df2)\n",
    "\n",
    "# Convert the encoded data to a DataFrame\n",
    "df3 = pd.DataFrame(df_encoded.toarray(), columns=transformer.get_feature_names_out(df2.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1389651",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df3.drop('remainder__contaminated', axis=1)\n",
    "y = df3['remainder__contaminated'].astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b802ba5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0969189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict probabilities for the positive class\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Compute AUC\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(\"AUC:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea86a46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the feature names from the DataFrame\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Create a DMatrix for feature importance\n",
    "dmatrix = xgb.DMatrix(X_train, feature_names=feature_names)\n",
    "\n",
    "# Retrieve the feature importance scores\n",
    "importance_scores = model.get_booster().get_score(importance_type='weight')\n",
    "\n",
    "# Create lists to store the feature names and importance scores\n",
    "features = []\n",
    "scores = []\n",
    "\n",
    "# Iterate over the feature importance scores\n",
    "for feature, score in importance_scores.items():\n",
    "    features.append(feature)\n",
    "    scores.append(score)\n",
    "\n",
    "# Sort the feature names and importance scores by score\n",
    "sorted_indices = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)\n",
    "sorted_features = [features[i] for i in sorted_indices]\n",
    "sorted_scores = [scores[i] for i in sorted_indices]\n",
    "\n",
    "# Plot the feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(sorted_features, sorted_scores)\n",
    "plt.xlabel('Importance Score')\n",
    "plt.ylabel('Features')\n",
    "plt.title('Variable Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51de815a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create the XGBoost classifier\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "\n",
    "# Setting the range for the hyperparameters\n",
    "param_grid = {\n",
    "    'max_depth': [3, 6, 9],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.3],\n",
    "    'reg_lambda': [0, 1, 10],\n",
    "    'reg_alpha': [0, 1, 10]\n",
    "}\n",
    "\n",
    "# Fitting grid search to the train data with 5 folds\n",
    "gridsearch = GridSearchCV(estimator=xgb_model, \n",
    "                          param_grid=param_grid,\n",
    "                          cv=StratifiedKFold(), \n",
    "                          scoring='roc_auc', \n",
    "                          verbose=2).fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a81f03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best model and best hyperparameters from the grid search\n",
    "best_xgb_model = gridsearch.best_estimator_\n",
    "\n",
    "# Make predictions on the test data using the best model\n",
    "y_pred = best_xgb_model.predict(X_test)\n",
    "\n",
    "# Compute AUC\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "print(\"AUC:\", auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
