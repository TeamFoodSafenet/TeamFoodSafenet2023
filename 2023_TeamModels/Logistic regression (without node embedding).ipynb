{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987da0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a92990",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "\n",
    "uri = \"bolt://localhost:7687\" \n",
    "username = \"neo4j\"     \n",
    "password = \"foodContamination\" #This is whatever password you set when you are created your database    \n",
    "\n",
    "driver = GraphDatabase.driver(uri, auth=(username, password))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b116b131",
   "metadata": {},
   "outputs": [],
   "source": [
    "cypher_query = \"\"\"MATCH (n) \n",
    "OPTIONAL MATCH (n)-[r]->(m) \n",
    "RETURN n, r, m\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0feb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "with driver.session() as session:\n",
    "    result = session.run(cypher_query)\n",
    "\n",
    "    # Extract properties and relationships from nodes\n",
    "    data = []\n",
    "    for record in result:\n",
    "        node = record['n']\n",
    "        properties = dict(node.items())\n",
    "        relationship = record['r']\n",
    "        if relationship is not None:\n",
    "            relationship_properties = dict(relationship.items())\n",
    "        else:\n",
    "            relationship_properties = {}\n",
    "        data.append({**properties, **relationship_properties})\n",
    "\n",
    "    # Create DataFrame from the data\n",
    "    df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3006dbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[['commodity','eventID', 'gtin', 'sgln', 'cteDate', 'pgln', 'contaminated', 'shortDescription']]\n",
    "#df2 = df[[ 'commodity', 'shortDescription','cteDate', 'gtin', 'contaminated']]\n",
    "df2 = df2.dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d5aec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['cteDate'] = pd.to_datetime(df2['cteDate'])\n",
    "reference_date = pd.to_datetime('1970-01-01')\n",
    "df2['cteDate'] = (df2['cteDate'] - reference_date).dt.days.astype(float)\n",
    "\n",
    "df2['commodity'] = df2['commodity'].fillna(df2['shortDescription'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf46daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.drop('shortDescription', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d13134",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['eventID'] = pd.to_numeric(df2['eventID'].str.replace('.', ''))\n",
    "df2['gtin'] = pd.to_numeric(df2['gtin'].str.replace('.', ''))\n",
    "df2['sgln'] = pd.to_numeric(df2['sgln'].str.replace('.', ''))\n",
    "df2['pgln'] = pd.to_numeric(df2['pgln'].str.replace('.', ''))\n",
    "#df2['parentID'] = pd.to_numeric(df2['parentID'].str.replace('.', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0582617e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the columns to be one-hot encoded\n",
    "columns_to_encode = ['commodity']\n",
    "\n",
    "# Create the ColumnTransformer\n",
    "transformer = ColumnTransformer([('one_hot_encoder', OneHotEncoder(), columns_to_encode)], remainder='passthrough')\n",
    "\n",
    "# Apply the transformation\n",
    "df_encoded = transformer.fit_transform(df2)\n",
    "\n",
    "# Convert the encoded data to a DataFrame\n",
    "df3 = pd.DataFrame(df_encoded.toarray(), columns=transformer.get_feature_names_out(df2.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1389651",
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns_to_drop = ['contaminated']\n",
    "#X = df_encoded.loc[:, ~df_encoded.columns.isin(columns_to_drop)]\n",
    "X = df3.drop('remainder__contaminated', axis=1)\n",
    "y = df3['remainder__contaminated']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b612a94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "\n",
    "# Setting the range for class weights and regularization values (C)\n",
    "weights = np.linspace(0.0, 0.99, 100)\n",
    "C_values = [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "# Creating a dictionary grid for grid search\n",
    "param_grid = {'class_weight': [{0: x, 1: 1.0 - x} for x in weights],\n",
    "              'C': C_values}\n",
    "\n",
    "#Fitting grid search to the train data with 5 folds\n",
    "gridsearch = GridSearchCV(estimator= lr, \n",
    "                          param_grid= param_grid,\n",
    "                          cv=StratifiedKFold(), \n",
    "                          n_jobs=-1, \n",
    "                          scoring='roc_auc', \n",
    "                          verbose=2).fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1586d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best class_weight and regularization value (C) from the grid search\n",
    "best_class_weight = gridsearch.best_params_['class_weight']\n",
    "best_C = gridsearch.best_params_['C']\n",
    "\n",
    "# Create the best logistic regression model with the best class_weight and C\n",
    "best_model = LogisticRegression(class_weight=best_class_weight, C=best_C)\n",
    "\n",
    "# Train the best model on the entire training data\n",
    "best_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4f1fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test data using the best model\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate the AUC score\n",
    "auc_score = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "print(\"AUC:\", auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6d9f67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the feature names (assuming X is a DataFrame or has column names)\n",
    "feature_names = X.columns.tolist()\n",
    "\n",
    "# Create a DataFrame to store feature names and their corresponding coefficients\n",
    "coeff_df = pd.DataFrame({'Feature': feature_names, 'Coefficient': best_model.coef_[0]})\n",
    "\n",
    "# Sort the features by their absolute coefficients (importance)\n",
    "coeff_df['Absolute Coefficient'] = np.abs(coeff_df['Coefficient'])\n",
    "coeff_df = coeff_df.sort_values(by='Absolute Coefficient', ascending=False)\n",
    "\n",
    "# Display the top 10 important features\n",
    "print(coeff_df.head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
